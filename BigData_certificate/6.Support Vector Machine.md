# Support Vector Manhine

> 서포트 벡터(Support Vectors)를 사용해서 결정 경계(Decision Boundary)를 정의하고 분류되지 않은 점을 해당 결정 경계와 비교해서 분류하는 지도학습 머신러닝 모델

```python
from sklearn.svm import SVC
# SVR은 수치 예측
md = SVC(C = 10, gamma = 1, random_state = 0, probability =True)
# probability = True는 반드시 추가해야한다.
md.fit(x_train,y_train)
print('score : ', md.score(x_train, y_train))
```

* 서포트 벡터와 결정 경계 사이의 거리를 마진(margin) 이라고 한다.
* C 는 허용되는 오류 양을 조절한다. C 값이 클수록 오류를 덜 허용하며 이를 하드 마진(hard margin)이라 한다. 반대로 C 값이 작을수록 오류를 더 많이 허용해 소프트 마진(Soft margin)을 만든다.
* gamma는 결정 경계를 얼마나 유연하게 그을 것인지 정해주는 파라미터로 학습데이터에 얼마나 민감하게 반응할 것인지 모델을 조정한다. 값이 높을수록 오버피팅을 유도할 수 있다. 반대로 작을수록 결정경계가 직선에 가까워져 언더피팅이 유도될 수 있다.

```python
pred = md.predict_proba(x_test) # 평가데이터에 대해서 확률 추정
pred = pd.DataFrame(pred) # DataFrame로 저장
pred = pred.iloc[:,1] 
```

```python
y_test = 'Jin.csv' # 수험번호로 제출할 내용
ans = pd.concat([x_id,pred], axis = 1)
ans.to_csv(y_test, index = False)
```

