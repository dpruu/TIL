# K-Nearest Neighbor

```python
from sklearn.neighbors import KNeighborsClassifier
# 수치 예측일 경우 Classifier가 아닌 다른 모델
md = KNeighborsClassifier(n_neighbors = 3, metric = 'euclidean')
# 이웃 수 5, euclidean 직선거리에 따른 이웃
md.fit(x_train, y_train) # 학습과정
print('score : ', md.score(x_train, y_train)) # 0.78
```

* n_neighbors를 조절해 영향 받을 이웃의 수를 고려한다.
* metric
  * `manhattan` : 점 사이의 거리를 격자형태로 측정하는 방식
  * `euclidean` : 점 사이의 직선 공식
  * `minkowski` : metric의 default 값으로 변수 p를 설정해줘야한다. p가 1일 경우 manhattan 방식을 사용, 2일 경우 euclidean 방식

```python
pred = md.predict_proba(x_test) # 평가데이터에 대해서 확률 추정
pred = pd.DataFrame(pred) # DataFrame로 저장
pred = pred.iloc[:,1] # 남자(1)일 확률 구해야 하기 때문에 iloc[:,1]
```

```python
y_test = 'Jin.csv'
ans = pd.concat([x_id,pred], axis = 1)
ans.to_csv(y_test, index = False)
ans
```

![image-20210720150104147](image\image-20210720150104147.png)